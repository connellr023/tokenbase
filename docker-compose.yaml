services:
  # Backend service
  backend:
    depends_on:
      - surrealdb
      - redis
      - tinyllama
    build:
      context: .
      dockerfile: ./build/package/dev/backend.dev.dockerfile
    volumes:
      - ./:/app
    ports:
      - "8090:8090"
    environment:
      - GO_ENV=development
    networks:
      - app-network

  # TinyLlama service (LLM container)
  tinyllama:
    build:
      context: .
      dockerfile: ./build/package/tinyllama.dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_KEEP_ALIVE=6m
      - OLLAMA_MAX_LOADED_MODELS=1
    networks:
      - app-network

  # Database service
  surrealdb:
    build:
      context: .
      dockerfile: ./build/package/surrealdb.dockerfile
    command: start --user root --pass root
    ports:
      - "8000:8000"
    volumes:
      - ./schema:/docker-entrypoint-initdb.d
    networks:
      - app-network

  # Cache service
  redis:
    build:
      context: .
      dockerfile: ./build/package/redis.dockerfile
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=password
    networks:
      - app-network

# Define the custom network
networks:
  app-network:
    driver: bridge
